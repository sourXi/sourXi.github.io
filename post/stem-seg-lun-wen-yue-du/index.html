<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>STEm-Seg论文阅读 | 酸希Hope_Tart</title>
<link rel="shortcut icon" href="https://sourxi.github.io//favicon.ico?v=1621872917526">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://sourxi.github.io//styles/main.css">
<link rel="alternate" type="application/atom+xml" title="STEm-Seg论文阅读 | 酸希Hope_Tart - Atom Feed" href="https://sourxi.github.io//atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



    <meta name="description" content="可能总是要给自己找点事做，于是最近误打误撞地在打天池的视频云比赛。
一直以来我对CV方向的理解都仅仅来源于知乎上的“黑帖”……以为CV已经到头了、不能更卷之类的。虽然对图像和图形学十分感兴趣，但一直敬而远之，没能深入。（我真的好想抽出一大段..." />
    <meta name="keywords" content="视频理解" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
    <script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://sourxi.github.io/">
  <img class="avatar" src="https://sourxi.github.io//images/avatar.png?v=1621872917526" alt="">
  </a>
  <h1 class="site-title">
    酸希Hope_Tart
  </h1>
  <p class="site-description">
    给时间以生命。Make time for life.
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          归档
        </a>
      
    
      
        <a href="/tags" class="menu">
          标签
        </a>
      
    
      
        <a href="/post/about" class="menu">
          关于
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              STEm-Seg论文阅读
            </h2>
            <div class="post-info">
              <span>
                2021-05-14
              </span>
              <span>
                4 min read
              </span>
              
                <a href="https://sourxi.github.io/tag/VoKwkAHeV/" class="post-tag">
                  # 视频理解
                </a>
              
            </div>
            
              <img class="post-feature-image" src="https://sourxi.github.io//post-images/stem-seg-lun-wen-yue-du.png" alt="">
            
            <div class="post-content-wrapper">
              <div class="post-content">
                <p>可能总是要给自己找点事做，于是最近误打误撞地在打天池的视频云比赛。</p>
<p>一直以来我对CV方向的理解都仅仅来源于知乎上的“黑帖”……以为CV已经到头了、不能更卷之类的。虽然对图像和图形学十分感兴趣，但一直敬而远之，没能深入。（我真的好想抽出一大段时间做动画啊哭o(╥﹏╥)o）</p>
<p>这次偶然接触了cv，感觉其实很好玩！未来也有不错的应用场景（饼）。至于比赛，这次是关于视频目标检测与分割的部分，之前已经阅读了很多Video Object/Instance Segmentation相关的paper，很多都不怎么合适。初赛阶段也一直只是跑跑<s>卡丁车</s>代码，感觉复赛再没有算法贡献就要被组委会踢了……所以下面总结一下最近效果还不错的一篇paper：STEm-Seg。<a href="https://arxiv.org/pdf/2003.08429.pdf">[paper]</a><a href="https://github.com/sabarim/STEm-Seg">[code]</a></p>
<h2 id="动机">动机</h2>
<p>之前的网络大多top-down + tracking-by-detection模型有多个网络组成，算力需求大，不是端到端。</p>
<h2 id="创新">创新</h2>
<p>bottom up + spatio-temporal</p>
<p>类别agnostic，同一物体的像素聚类</p>
<ol>
<li>适应多场景欠标注条件</li>
<li>聚类</li>
<li>单网络</li>
</ol>
<h2 id="方法">方法</h2>
<p><strong>输入：</strong> <u>T*W*H</u>（N）*3</p>
<p><strong>输出：</strong> ①每个像素的embedding N*E ②每个像素和每个维度的方差N*E 3⃣️ object instance center heatmap</p>
<p><strong>Instance表示：</strong><br>
1. 计算均值+方差<br>
2. 计算像素属于该类别的概率<br>
3. threshhold p&gt;0.5</p>
<p><strong>训练：</strong> 可训练的参数——均值&amp;方差；目标函数——IoU（4）；loss函数——三个</p>
<p><strong>Embedding表示：</strong> 自身+位置信息（xi，yi，ti），2d变3d，也可以free dimension，但不是越多越好</p>
<p><strong>Infer 流程：</strong></p>
<figure data-type="image" tabindex="1"><img src="https://pic2.zhimg.com/v2-aeecb1b2601ce3ef90b0d38ff8731639_r.jpg" alt="preview" loading="lazy"></figure>
<p>（1）根据Heatmap选出instance的中心点；</p>
<p>（2）找到该中心点所对应的embedding和方差向量；</p>
<p>（3）将该instance的均值和方差用这个中心点所对应的来表示，并通过计算公式（2），来判断某个pixel属于该实例的概率；</p>
<p>（4）由于一些像素已经分配到实例j中，所以为了更长远的考虑，将他们的信息剔除掉</p>
<p>（5）重复1-4的操作，直到Heatmap为空集，或者最大值小于我们设定的threshold。</p>
<p>内存限制，视频切分</p>
<p><strong>网络结构：</strong></p>
<p>1 encoder + 2 decoders</p>
<p>encoder：FPN 4 scales</p>
<p>decoder：ResNet101 3d conv + pooling（内存：size大的layer少）</p>
<figure data-type="image" tabindex="2"><img src="https://pic4.zhimg.com/v2-6848dffeb64453ccd31c31dd133d2b13_r.jpg" alt="preview" loading="lazy"></figure>
<h2 id="一些问题">一些问题</h2>
<ol>
<li>
<p>heatmap是怎么学习到物体center的？<mark>open</mark></p>
<p>H(ci)代表probability，argmax H(ci)代表概率最高的点，也就是center吧。</p>
<p>追问：H是啥？看了代码，认为H只是在做几次down sample，结果可以看做一个feature map或者就是conv+pooling，但是很多地方都称为heatmap。但是与center的关系？</p>
</li>
<li>
<p>训练过程里embedding head是在优化mean和covariance，如何理解这个covariance？</p>
<p>边界？<code>closed</code></p>
<p>方差小的像素点和均值点比较相似，更容易属于同一物体；方差大的地方差异大，变化剧烈，可以被划成其他物体。</p>
</li>
<li>
<p>infer过程中的step 2：“Find the corresponding embedding vector E(cj) and variances V(cj).”不存在点的集合，如何计算方差V(cj)？<code>closed</code></p>
<p>集合是图片中所有像素点，均值是计算所有点的均值。得到中心点后，以中心点为均值，计算对应方差，从而得到预测的mask。最后把mask中的点从图片中抠掉。重复。</p>
<p>上述是猜测，未代码证实。如果是这样，那么有一点疑惑：semantic segmentation？还是要搞清楚Heatmap到底咋算的。只有animals？图让我又傻了。</p>
<p>续：有threshhold啊笨蛋。背景什么的值会非常低，但是那时已经不会再考虑了。以及后续实验验证，threshold调低效果会更好…… 调到0.1之后分数直接涨了1% orz……</p>
</li>
</ol>

              </div>
              <div class="toc-container">
                <ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#%E5%8A%A8%E6%9C%BA">动机</a></li>
<li><a href="#%E5%88%9B%E6%96%B0">创新</a></li>
<li><a href="#%E6%96%B9%E6%B3%95">方法</a></li>
<li><a href="#%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98">一些问题</a></li>
</ul>
</li>
</ul>

              </div>
            </div>
          </article>
        </div>

        
          <div class="next-post">
            <div class="next">下一篇</div>
            <a href="https://sourxi.github.io/post/self-driving-udacity/">
              <h3 class="post-title">
                Self-driving Udacity
              </h3>
            </a>
          </div>
        

        
          
            <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>

<div id="gitalk-container"></div>

<script>

  var gitalk = new Gitalk({
    clientID: '',
    clientSecret: '',
    repo: '',
    owner: '',
    admin: [''],
    id: (location.pathname).substring(0, 49),      // Ensure uniqueness and length less than 50
    distractionFreeMode: false  // Facebook-like distraction free mode
  })

  gitalk.render('gitalk-container')

</script>

          

          
        

        <div class="site-footer">
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a>
  <a class="rss" href="https://sourxi.github.io//atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>

    <script>
      hljs.initHighlightingOnLoad()

      let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

      // This should probably be throttled.
      // Especially because it triggers during smooth scrolling.
      // https://lodash.com/docs/4.17.10#throttle
      // You could do like...
      // window.addEventListener("scroll", () => {
      //    _.throttle(doThatStuff, 100);
      // });
      // Only not doing it here to keep this Pen dependency-free.

      window.addEventListener("scroll", event => {
        let fromTop = window.scrollY;

        mainNavLinks.forEach((link, index) => {
          let section = document.getElementById(decodeURI(link.hash).substring(1));
          let nextSection = null
          if (mainNavLinks[index + 1]) {
            nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
          }
          if (section.offsetTop <= fromTop) {
            if (nextSection) {
              if (nextSection.offsetTop > fromTop) {
                link.classList.add("current");
              } else {
                link.classList.remove("current");    
              }
            } else {
              link.classList.add("current");
            }
          } else {
            link.classList.remove("current");
          }
        });
      });

    </script>
  </body>
</html>
